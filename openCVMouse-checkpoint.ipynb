{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93baba5",
   "metadata": {},
   "source": [
    "#  Resources:https://www.youtube.com/watch?v=01sAkU_NvOY&t=12503s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72cd7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8774973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "speakingMode = True\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as w\n",
    "from selenium.webdriver.support import expected_conditions as e\n",
    "from pynput.keyboard import Controller\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SpeakingMode():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def speakToWrite(self):\n",
    "        self.speakingMode = True\n",
    "        self.keyboard = Controller()\n",
    "        self.recognition = sr.Recognizer()\n",
    "        while self.speakingMode:\n",
    "            with sr.Microphone() as self.mic:\n",
    "                try:\n",
    "                    self.recognition.adjust_for_ambient_noise(self.mic)\n",
    "                    print(\"say:\")\n",
    "                    self.audio = self.recognition.listen(self.mic)\n",
    "                    self.text = self.recognition.recognize_google(self.audio)\n",
    "                    print(\"You said: \"+ self.text)\n",
    "                    if self.text.lower() == \"enough\":\n",
    "                        self.speakingMode = False\n",
    "                    elif self.text.lower() == \"open website mode\":\n",
    "                        self.openWebsite()\n",
    "                        self.speakingMode = False\n",
    "                    else:\n",
    "                        for letter in self.text:\n",
    "                            self.keyboard.press(letter)\n",
    "                except Exception as exc:\n",
    "                    print(\"Error please try again \")\n",
    "    def openWebsite(self):\n",
    "        self.speakingMode = True\n",
    "        self.keyboard = Controller()\n",
    "        self.recognition = sr.Recognizer()\n",
    "        self.path = r\"C:/Users/Fatih/computer vision/mouse/chromedriver.exe\" \n",
    "        while self.speakingMode:\n",
    "            with sr.Microphone() as self.mic:\n",
    "                try:\n",
    "                    self.recognition.adjust_for_ambient_noise(self.mic)\n",
    "                    print(\"say:\")\n",
    "                    self.audio = self.recognition.listen(self.mic)\n",
    "                    self.text = self.recognition.recognize_google(self.audio)\n",
    "                    print(\"You said: \"+ self.text) \n",
    "                    if self.text.lower() == \"enough\":\n",
    "                        self.speakingMode = False\n",
    "                    elif self.text.lower() == \"open write mode\":\n",
    "                        self.speakToWrite()\n",
    "                        self.speakingMode = False\n",
    "                    elif self.text.lower()[:4] == \"open\":\n",
    "                        self.ser = Service(r\"C:/Users/Fatih/computer vision/mouse/chromedriver.exe\")\n",
    "                        self.options = ChromeOptions()\n",
    "                        self.options.add_argument(\"--headless--\")\n",
    "                        self.browser = webdriver.Chrome(service=self.ser)\n",
    "                        self.searchWords = self.text.split()\n",
    "                        print(self.searchWords[1:])\n",
    "                        self.baseLink = \"https://www.google.com/search?q=\"\n",
    "                        for i in range(1,len(self.searchWords)):\n",
    "                            self.baseLink += str(self.searchWords[i])\n",
    "                            self.baseLink += \"+\"\n",
    "                        print(self.baseLink)\n",
    "                        self.browser.get(self.baseLink)\n",
    "                        \"\"\"\n",
    "                        self.browser.get(\"https://www.google.com\")\n",
    "                        self.waitVariable = w(self.browser, 1)\n",
    "                        self.googleInput = self.browser.find_element(By.XPATH, \"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\")\n",
    "                        self.googleInput.send_keys(self.text[5:])\n",
    "                        self.googleInput.send_keys(Keys.ENTER)\n",
    "                        \"\"\"\n",
    "                        self.waitVariable = w(self.browser, 1)\n",
    "                        self.waitVariable.until(e.element_to_be_clickable((By.PARTIAL_LINK_TEXT, self.text[5:]))).click()\n",
    "                    if self.text.lower()[:4] == \"play\":\n",
    "                        self.searchWords = self.text.split()\n",
    "                        print(self.searchWords[1:])\n",
    "                        self.baseLink = \"https://www.youtube.com/results?search_query=\"\n",
    "                        for i in range(1,len(self.searchWords)):\n",
    "                            self.baseLink += str(self.searchWords[i])\n",
    "                            self.baseLink += \"+\"\n",
    "                        print(self.baseLink)\n",
    "                        self.ser = Service(r\"C:/Users/Fatih/computer vision/mouse/chromedriver.exe\")\n",
    "                        self.browser = webdriver.Chrome(service=self.ser)\n",
    "                        self.browser.get(self.baseLink)\n",
    "                        self.waitVariable = w(self.browser, 1)\n",
    "                        self.waitVariable.until(e.element_to_be_clickable((By.PARTIAL_LINK_TEXT, self.text[5:]))).click()\n",
    "                except Exception as exc:\n",
    "                    print(\"Error please try again \", exc)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c574d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say:\n",
      "You said: open YouTube\n",
      "['YouTube']\n",
      "https://www.google.com/search?q=YouTube+\n",
      "say:\n",
      "Error please try again  \n",
      "say:\n",
      "You said: open BBC News\n",
      "['BBC', 'News']\n",
      "https://www.google.com/search?q=BBC+News+\n",
      "say:\n",
      "You said: enough\n"
     ]
    }
   ],
   "source": [
    "a = SpeakingMode()\n",
    "a.openWebsite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18af71d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaking mode active\n",
      "say:\n",
      "You said: hell no\n",
      "say:\n",
      "You said: open\n",
      "say:\n",
      "You said: enough\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3d8c6ad125c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlineInfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineInfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[0mautopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmouse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmouse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mButton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEFT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import autopy\n",
    "capture = cv2.VideoCapture(0)\n",
    "import numpy as np\n",
    "import math\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "from numpy import log as ln\n",
    "from comtypes import CLSCTX_ALL\n",
    "from ctypes import cast, POINTER\n",
    "\n",
    "class handDetector():\n",
    "    def __init__(self,staticMode=False,maxHands=2,detectionCon=0.5,trackingCon=0.5):\n",
    "        self.staticMode = staticMode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackingCon = trackingCon\n",
    "        self.mphands = mp.solutions.hands\n",
    "        self.hands = self.mphands.Hands(self.staticMode, self.maxHands,1, self.detectionCon, self.trackingCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "    def findHands(self, image, draw=True):\n",
    "        imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imageRGB)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for point in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(image, point, self.mphands.HAND_CONNECTIONS)\n",
    "                \"\"\"\n",
    "                for id, lm in enumerate(point.landmark):\n",
    "                h, w, c = image.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                print(id, cx, cy)\n",
    "                cv2.circle(image, (cx, cy), 10, (0, 255, 255), cv2.FILLED)                \n",
    "                \"\"\"\n",
    "        return image\n",
    "    def findPosition(self, image, handNo=0, draw=True):\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        self.lmList = []\n",
    "        image = self.findHands(image)\n",
    "        \n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h, w, c = image.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                self.lmList.append([id,cx,cy])\n",
    "                if draw:\n",
    "                    cv2.circle(image, (cx, cy), 10, (255, 255, 255), cv2.FILLED)\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox.append([xmin, ymin, xmax, ymax])\n",
    "            \"\"\"\n",
    "            if draw:\n",
    "                    cv2.rectangle(image, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20) (255, 255, 255), 2)\n",
    "                    \"\"\"\n",
    "        return self.lmList, bbox \n",
    "    def fingersUp(self):\n",
    "        fingers = []\n",
    "        if len(lmList) > 0:\n",
    "            if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        for id in range(1,5):\n",
    "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "        return fingers\n",
    "\n",
    "    def findDistance(self, p1, p2, image, draw=True, r=15, t=3):\n",
    "        succes, image = capture.read()\n",
    "        imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imageRGB)\n",
    "\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (255, 255, 0), 3)\n",
    "        cv2.circle(image, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(image, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.circle(image, (cx, cy), 10, (0, 0, 255), cv2.FILLED)\n",
    "        #self.mpDraw.draw_landmarks(image, point, mphands.HAND_CONNECTIONS)\n",
    "        lenght = math.hypot(x2 - x1, y2 - y1)\n",
    "        return lenght, image, [x1, y1, x2, y2, cx, cy]\n",
    "        if results.multi_hand_landmarks:\n",
    "\n",
    "            for point in results.multi_hand_landmarks:\n",
    "                for id, lm in enumerate(point.landmark):\n",
    "                    if id == 4:\n",
    "                        h, w, c = image.shape\n",
    "                        x1, y1 = int(lm.x * w), int(lm.y * h)\n",
    "                    if id == 8:\n",
    "                        h, w, c = image.shape\n",
    "                        x2, y2 = int(lm.x * w), int(lm.y * h)\n",
    "                cv2.circle(image, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n",
    "                cv2.circle(image, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "                if ((x1 + x2) != 0 or (y1 + y2) != 0):\n",
    "                    xm, ym = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                print(lenght)\n",
    "                vol = np.interp(int(lenght), [50, 500], [minVolume, maxVolume])\n",
    "                volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "wCam = 1280\n",
    "hCam = 720\n",
    "capture.set(3, wCam)\n",
    "capture.set(4, hCam)\n",
    "wscr, hscr = autopy.screen.size()\n",
    "\n",
    "prevX, prevY = 0, 0\n",
    "currX, currY = 0, 0\n",
    "\n",
    "frameReduction = 250\n",
    "smoothening = 5\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "vol = 0\n",
    "volumeBar = 0\n",
    "minVolume = -96\n",
    "maxVolume = 0\n",
    "volumeBar = 150\n",
    "savingVolume = 0\n",
    "setSavingVolume = False\n",
    "\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "detector = handDetector(maxHands=1)\n",
    "\n",
    "speaker = SpeakingMode()\n",
    "\"\"\"\n",
    "mphands = mp.solutions.hands\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "hands = mphands.Hands()\n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    \n",
    "    speakingMode = False\n",
    "    \n",
    "    succes, image = capture.read()\n",
    "    #image = detector.findHands(image)\n",
    "    lmList, boxList = detector.findPosition(image, False)\n",
    "    cv2.rectangle(image, (frameReduction, frameReduction), (wCam - frameReduction, hCam - frameReduction),\n",
    "                         (255,255,0), 2)\n",
    "    if len(lmList) !=0:\n",
    "        x1, y1 = lmList[8][1:]\n",
    "        x2, y2 = lmList[12][1:]\n",
    "    \n",
    "        fingers = detector.fingersUp()\n",
    "        \n",
    "        if fingers[0] == 0 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            speakingMode = True\n",
    "            print(\"Speaking mode active\")\n",
    "            speaker.speakToWrite()\n",
    "        \n",
    "        if fingers[1] == 1 and fingers[2] == 0 and fingers[0] == 0:\n",
    "            if setSavingVolume:\n",
    "                volume.SetMasterVolumeLevel(savingVolume, None)\n",
    "            x3 = np.interp(x1, (frameReduction, wCam - frameReduction), (0,wscr))\n",
    "            y3 = np.interp(y1, (frameReduction, hCam - frameReduction), (0,hscr))\n",
    "            \n",
    "            currX = prevX + (x3 - prevX) / smoothening\n",
    "            currY = prevY + (y3 - prevY) / smoothening\n",
    "            \n",
    "            \n",
    "            autopy.mouse.move(wscr - currX, currY)\n",
    "            cv2.circle(image, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
    "            prevX, prevY = currX, currY\n",
    "        elif fingers[0] == 1 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 0 and fingers[4] == 1:          \n",
    "\n",
    "            savingVolume = volume.GetMasterVolumeLevel()\n",
    "            setSavingVolume = True\n",
    "            \n",
    "        elif fingers[0] == 1 and fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1 and fingers[4] == 1:                    \n",
    "            lenght, image, lineInfo = detector.findDistance(4, 8, image)\n",
    "            vol = np.interp(ln(lenght), [ln(40), ln(300)], [minVolume, maxVolume])\n",
    "            volumeBar = np.interp(ln(lenght), [ln(10), ln(300)], [400, 100])\n",
    "            volume.SetMasterVolumeLevel(vol, None)\n",
    "            cv2.circle(image, (lineInfo[4], lineInfo[5]), 15, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.rectangle(image, (50, 100), (90, 400), (0, 255, 255), 5)\n",
    "            cv2.rectangle(image, (50, int(volumeBar)), (90, 400), (0, 255, 255), cv2.FILLED)\n",
    "            time.sleep(0.01)\n",
    "        elif fingers[0] == 1 and fingers[1] == 1 and fingers[4] == 1:\n",
    "            if setSavingVolume:\n",
    "                volume.SetMasterVolumeLevel(savingVolume, None)\n",
    "            lenght, image, lineInfo = detector.findDistance(8, 12, image)\n",
    "            if lenght < 30:\n",
    "                cv2.circle(image, (lineInfo[4], lineInfo[5]), 15, (255, 0, 255), cv2.FILLED)\n",
    "                autopy.mouse.click(autopy.mouse.Button.RIGHT)\n",
    "                time.sleep(0.31)\n",
    "        elif fingers[1] == 1 and fingers[2] == 1:\n",
    "            if setSavingVolume:\n",
    "                volume.SetMasterVolumeLevel(savingVolume, None)\n",
    "            lenght, image, lineInfo = detector.findDistance(8, 12, image)\n",
    "            if lenght < 30:\n",
    "                cv2.circle(image, (lineInfo[4], lineInfo[5]), 15, (255, 0, 255), cv2.FILLED)\n",
    "                autopy.mouse.click(autopy.mouse.Button.LEFT)\n",
    "                time.sleep(0.31)\n",
    "        \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    if results.multi_hand_landmarks:\n",
    "\n",
    "        for point in results.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(point.landmark):\n",
    "                if id == 4:\n",
    "                    h, w, c = image.shape\n",
    "                    x1, y1 = int(lm.x * w), int(lm.y * h)\n",
    "                if id == 8:\n",
    "                    h, w, c = image.shape\n",
    "                    x2, y2 = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(image, (x1,y1), 10, (0,0,255), cv2.FILLED)\n",
    "            cv2.circle(image, (x2,y2), 10, (0,0,255), cv2.FILLED)\n",
    "\n",
    "            if ((x1+x2) != 0 or (y1+y2) != 0):\n",
    "                xm, ym = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                cv2.circle(image, (xm,ym), 10, (0,0,255), cv2.FILLED)\n",
    "            mpDraw.draw_landmarks(image, point, mphands.HAND_CONNECTIONS)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 255, 0), 3)\n",
    "\n",
    "            lenght = math.hypot(x2 - x1, y2 - y1)\n",
    "            print(lenght)\n",
    "            vol = np.interp(int(lenght), [50, 500], [minVolume, maxVolume])\n",
    "            volume.SetMasterVolumeLevel(vol, None)\n",
    "    \"\"\"    \n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime - previousTime)\n",
    "    previousTime = currentTime\n",
    "    cv2.putText(\n",
    "        image, str(int(fps)), (20, 60), cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 2\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
